# ImportarDGII - Documentaci√≥n para Integraci√≥n API

## Descripci√≥n General

**ImportarDGII** es un sistema para importar archivos Excel de Facturaci√≥n Electr√≥nica (FE) de la DGII hacia una base de datos SQL Server. El sistema procesa archivos Excel con estructura espec√≠fica de encabezados y detalles de facturas electr√≥nicas, validando duplicados y manteniendo la integridad de los datos.

Este documento se enfoca en los componentesÊ†∏ÂøÉ del sistema que pueden ser integrados en una API web, **omitiendo la interfaz gr√°fica (PyQt6)**.

---

## Arquitectura del Sistema

### Estructura de Directorios

```
ImportarExcelSQL_v4/
‚îú‚îÄ‚îÄ config/                          # Archivos de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ settings.json               # Configuraci√≥n de conexi√≥n DB
‚îÇ   ‚îú‚îÄ‚îÄ encabezado_columns.json     # Definici√≥n columnas encabezado
‚îÇ   ‚îî‚îÄ‚îÄ detalle_columns.json        # Definici√≥n columnas detalle
‚îú‚îÄ‚îÄ core/                           # L√≥gica de negocio (API-ready)
‚îÇ   ‚îú‚îÄ‚îÄ db_manager.py               # Gesti√≥n de base de datos
‚îÇ   ‚îî‚îÄ‚îÄ excel_loader.py             # Carga y limpieza de Excel
‚îú‚îÄ‚îÄ ui/                             # Interfaz gr√°fica (ignorar para API)
‚îÇ   ‚îú‚îÄ‚îÄ main_window.py
‚îÇ   ‚îî‚îÄ‚îÄ config_window.py
‚îú‚îÄ‚îÄ main.py                         # Punto de entrada GUI (ignorar)
‚îî‚îÄ‚îÄ requirements.txt                # Dependencias Python
```

---

## Componentes Principales para API

### 1. **M√≥dulo: `excel_loader.py`**

**Ubicaci√≥n:** `core/excel_loader.py`

**Prop√≥sito:** Cargar y limpiar datos de archivos Excel.

#### Funci√≥n Principal: `load_excel()`

```python
def load_excel(path_excel: str) -> pd.DataFrame:
    """
    Lee el Excel y reemplaza valores especiales con None (NULL):
    - Celdas vac√≠as ‚Üí None
    - '#e' / '#E' ‚Üí None
    - 'NULL' ‚Üí None
    - 'nan', 'NaN' ‚Üí None
    - Espacios en blanco ‚Üí None
    
    Args:
        path_excel: Ruta completa al archivo Excel (.xlsx)
    
    Returns:
        pd.DataFrame: DataFrame con datos limpios
    """
```

**Uso en API:**
```python
from core.excel_loader import load_excel

# Cargar archivo Excel subido por el usuario
df = load_excel("/path/to/uploaded/file.xlsx")
```

**Caracter√≠sticas:**
- Limpia autom√°ticamente valores nulos/inv√°lidos
- Convierte errores de Excel (#e, #E) a None
- Preserva tipos de datos como strings para validaci√≥n posterior
- Engine: `openpyxl` para compatibilidad con .xlsx

---

### 2. **M√≥dulo: `db_manager.py`**

**Ubicaci√≥n:** `core/db_manager.py`

**Prop√≥sito:** Gestionar conexi√≥n, esquema y operaciones con SQL Server.

#### Funciones Clave para API

##### 2.1 `load_settings()` y `save_settings()`

```python
def load_settings() -> Dict[str, str]:
    """Carga configuraci√≥n desde config/settings.json"""
    
def save_settings(cfg: dict) -> None:
    """Guarda configuraci√≥n en config/settings.json"""
```

**Configuraci√≥n requerida (`settings.json`):**
```json
{
  "server": "localhost",
  "database": "ImportarFE",
  "user": "SISTEMA",
  "password": "@@sistema",
  "table_encabezado": "FEEncabezado",
  "table_detalle_prefix": "FEDetalle",
  "driver": "ODBC Driver 17 for SQL Server",
  "validate_duplicates": true,
  "theme": "dark"
}
```

**Par√°metros importantes:**
- `server`: Servidor SQL Server (IP o hostname)
- `database`: Nombre de la base de datos
- `user` / `password`: Credenciales de autenticaci√≥n
- `table_encabezado`: Nombre de tabla para encabezados de facturas
- `table_detalle_prefix`: Prefijo para tabla(s) de detalles
- `driver`: Driver ODBC (t√≠picamente "ODBC Driver 17 for SQL Server")
- `validate_duplicates`: Si `true`, evita insertar registros duplicados

---

##### 2.2 `ensure_database_exists()`

```python
def ensure_database_exists() -> None:
    """
    Crea la base de datos si no existe.
    Usa conexi√≥n AUTOCOMMIT para evitar errores.
    """
```

**Uso en API:**
```python
from core.db_manager import ensure_database_exists

# Llamar al iniciar la aplicaci√≥n o endpoint
ensure_database_exists()
```

---

##### 2.3 `ensure_tables_exist()`

```python
def ensure_tables_exist(df: pd.DataFrame, recreate_mode: bool = False) -> List[str]:
    """
    Garantiza que las tablas est√©n listas.
    
    Args:
        df: DataFrame con los datos a importar
        recreate_mode: 
            - True: Elimina y recrea tablas (borra datos existentes)
            - False: Preserva datos existentes (modo append)
    
    Returns:
        Lista de nombres de tablas creadas/validadas
    """
```

**Modos de operaci√≥n:**

1. **Modo RECREAR** (`recreate_mode=True`):
   - Elimina tablas existentes
   - Recrea con esquema JSON
   - **¬°PRECAUCI√ìN!** Borra todos los datos

2. **Modo AGREGAR** (`recreate_mode=False`):
   - Sincroniza esquema sin borrar datos
   - Agrega columnas faltantes
   - Ajusta tipos de datos si difieren

**Uso en API:**
```python
from core.db_manager import ensure_tables_exist

# Modo agregar (recomendado para producci√≥n)
ensure_tables_exist(df, recreate_mode=False)

# Modo recrear (solo para desarrollo/testing)
ensure_tables_exist(df, recreate_mode=True)
```

---

##### 2.4 `split_dataframe()`

```python
def split_dataframe(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    Divide el DataFrame Excel en:
    1. Encabezado (df_head): Columnas definidas en encabezado_columns.json
    2. Detalle (det_tables): Columnas indexadas [1], [2], [3]... transpuestas a filas
    
    Returns:
        Tuple[pd.DataFrame, Dict[str, pd.DataFrame]]:
            - df_head: DataFrame de encabezados
            - det_tables: Diccionario {'FEDetalle': df_detalle}
    """
```

**Comportamiento:**
- **Filtrado por JSON**: Solo procesa columnas definidas en archivos JSON
- **Transposici√≥n de detalles**: Convierte columnas horizontales `Campo[1]`, `Campo[2]`... en filas verticales
- **Validaci√≥n de datos**: Filtra √≠tems sin `CantidadItem` v√°lida
- **Normalizaci√≥n**: Remueve corchetes de nombres (`FormaPago[1]` ‚Üí `FormaPago1`)

**Ejemplo de transformaci√≥n:**

**Excel original (horizontal):**
| eNCF | RNCEmisor | NumeroLinea[1] | CantidadItem[1] | NumeroLinea[2] | CantidadItem[2] |
|------|-----------|----------------|-----------------|----------------|-----------------|
| E001 | 123456789 | 1              | 10              | 2              | 5               |

**Detalle transpuesto (vertical):**
| eNCF | RNCEmisor | NumeroLinea | CantidadItem |
|------|-----------|-------------|--------------|
| E001 | 123456789 | 1           | 10           |
| E001 | 123456789 | 2           | 5            |

---

##### 2.5 `insert_dataframes()`

```python
def insert_dataframes(
    df_head: pd.DataFrame, 
    det_tables: Dict[str, pd.DataFrame]
) -> Tuple[int, Dict[str, int]]:
    """
    Inserta encabezados y detalles en SQL Server.
    
    Args:
        df_head: DataFrame de encabezados
        det_tables: Diccionario de DataFrames de detalles
    
    Returns:
        Tuple[int, Dict[str, int]]:
            - N√∫mero de encabezados insertados
            - Diccionario con filas insertadas por tabla de detalle
    """
```

**Caracter√≠sticas:**
- **Validaci√≥n de duplicados**: Si `validate_duplicates=true`, verifica `ENCF` + `RNCEmisor`
- **Modo append**: Siempre agrega datos, nunca reemplaza
- **Conversi√≥n autom√°tica de tipos**:
  - INT: `TipoECF`, `TipoPago`, etc.
  - BIT (booleano): `IndicadorNotaCredito`, etc.
  - DATE: `FechaEmision`, `FechaEntrega`, etc.
  - DECIMAL: Montos, cantidades, precios
- **Columnas autom√°ticas**: Agrega `fechacreacion` y `Modificado` con timestamp actual

**Uso en API:**
```python
from core.db_manager import insert_dataframes

head_count, detail_counts = insert_dataframes(df_head, det_tables)
print(f"Insertados: {head_count} encabezados, {sum(detail_counts.values())} detalles")
```

---

##### 2.6 `test_connection()`

```python
def test_connection() -> Tuple[bool, str]:
    """
    Prueba la conexi√≥n a SQL Server.
    
    Returns:
        Tuple[bool, str]: (√©xito, mensaje de error si fall√≥)
    """
```

**Uso en API:**
```python
from core.db_manager import test_connection

success, error_msg = test_connection()
if not success:
    return {"error": f"Conexi√≥n fallida: {error_msg}"}, 500
```

---

### 3. **Archivos de Configuraci√≥n JSON**

#### 3.1 `config/settings.json`

Configuraci√≥n de conexi√≥n y comportamiento del sistema.

```json
{
  "server": "localhost",
  "database": "ImportarFE",
  "user": "SISTEMA",
  "password": "@@sistema",
  "table_encabezado": "FEEncabezado",
  "table_detalle_prefix": "FEDetalle",
  "driver": "ODBC Driver 17 for SQL Server",
  "validate_duplicates": true,
  "theme": "dark"
}
```

**Par√°metros configurables:**
- Conexi√≥n DB: `server`, `database`, `user`, `password`, `driver`
- Nombres de tablas: `table_encabezado`, `table_detalle_prefix`
- Comportamiento: `validate_duplicates` (evitar duplicados)
- UI: `theme` (ignorar en API)

---

#### 3.2 `config/encabezado_columns.json`

Define el esquema de la tabla de encabezados.

**Estructura:**
```json
{
  "NombreColumna": {
    "type": "NVARCHAR | DECIMAL | DATE | INT | BIT",
    "length": 100,          // Solo para NVARCHAR
    "precision": 18,        // Solo para DECIMAL
    "scale": 4,             // Solo para DECIMAL
    "nullable": true,
    "description": "Descripci√≥n del campo"
  }
}
```

**Ejemplo:**
```json
{
  "TipoECF": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "Tipo de comprobante fiscal electr√≥nico"
  },
  "eNCF": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "N√∫mero de comprobante fiscal electr√≥nico"
  },
  "FechaEmision": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "Fecha de emisi√≥n de la factura"
  },
  "MontoTotal": {
    "type": "DECIMAL",
    "precision": 18,
    "scale": 4,
    "nullable": true,
    "description": "Monto total de la factura"
  }
}
```

**Columnas cr√≠ticas (Primary Key):**
- `ENCF`: N√∫mero de comprobante fiscal (parte de PK compuesta)
- `RNCEmisor`: RNC del emisor (parte de PK compuesta)

---

#### 3.3 `config/detalle_columns.json`

Define el esquema de la tabla de detalles (√≠tems de facturas).

**Estructura:** Igual que `encabezado_columns.json`

**Ejemplo:**
```json
{
  "NumeroLinea": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "N√∫mero de l√≠nea del √≠tem"
  },
  "TipoCodigo1": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "Tipo de c√≥digo del √≠tem [1]"
  },
  "CodigoItem1": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "C√≥digo del √≠tem [1]"
  },
  "CantidadItem": {
    "type": "NVARCHAR",
    "length": 100,
    "nullable": true,
    "description": "Cantidad del √≠tem"
  },
  "PrecioUnitarioItem": {
    "type": "DECIMAL",
    "precision": 18,
    "scale": 4,
    "nullable": true,
    "description": "Precio unitario del √≠tem"
  }
}
```

**Columnas indexadas:**
- Campos como `TipoCodigo[1]`, `TipoCodigo[2]`, `TipoCodigo[3]` se definen sin √≠ndice en JSON
- El sistema detecta autom√°ticamente los √≠ndices `[1]`, `[2]`, `[3]`... en el Excel
- Los transpone a filas separadas con `NumeroLinea` como identificador

---

## Flujo de Trabajo Completo para API

### Flujo Recomendado

```python
from core.excel_loader import load_excel
from core.db_manager import (
    ensure_database_exists,
    ensure_tables_exist,
    split_dataframe,
    insert_dataframes,
    test_connection
)

# 1. Validar conexi√≥n
success, error = test_connection()
if not success:
    raise Exception(f"Error de conexi√≥n: {error}")

# 2. Asegurar que la BD existe
ensure_database_exists()

# 3. Cargar Excel
df = load_excel("/ruta/archivo.xlsx")

# 4. Crear/validar tablas (modo append recomendado)
ensure_tables_exist(df, recreate_mode=False)

# 5. Dividir en encabezado y detalle
df_head, det_tables = split_dataframe(df)

# 6. Insertar en base de datos
head_count, detail_counts = insert_dataframes(df_head, det_tables)

# 7. Respuesta
response = {
    "success": True,
    "encabezados_insertados": head_count,
    "detalles_insertados": sum(detail_counts.values()),
    "tablas_detalle": detail_counts
}
```

---

## Ejemplo de Endpoint FastAPI

```python
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import tempfile
import os
from pathlib import Path

# Importar m√≥dulos del sistema
from core.excel_loader import load_excel
from core.db_manager import (
    ensure_database_exists,
    ensure_tables_exist,
    split_dataframe,
    insert_dataframes,
    test_connection
)

app = FastAPI(title="ImportarDGII API")

@app.post("/api/importar-excel")
async def importar_excel(
    file: UploadFile = File(...),
    recreate: bool = False  # Query param: ?recreate=true
):
    """
    Importa un archivo Excel de facturas DGII a SQL Server.
    
    Args:
        file: Archivo Excel (.xlsx)
        recreate: Si true, recrea tablas (¬°borra datos existentes!)
    
    Returns:
        JSON con resultados de la importaci√≥n
    """
    
    # Validar tipo de archivo
    if not file.filename.endswith('.xlsx'):
        raise HTTPException(
            status_code=400, 
            detail="Solo se permiten archivos .xlsx"
        )
    
    # Guardar archivo temporal
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = tmp.name
    
    try:
        # 1. Validar conexi√≥n
        success, error = test_connection()
        if not success:
            raise HTTPException(
                status_code=500,
                detail=f"Error de conexi√≥n a DB: {error}"
            )
        
        # 2. Asegurar BD existe
        ensure_database_exists()
        
        # 3. Cargar Excel
        df = load_excel(tmp_path)
        
        if len(df) == 0:
            raise HTTPException(
                status_code=400,
                detail="El archivo Excel est√° vac√≠o"
            )
        
        # 4. Crear/validar tablas
        ensure_tables_exist(df, recreate_mode=recreate)
        
        # 5. Dividir datos
        df_head, det_tables = split_dataframe(df)
        
        if len(df_head) == 0:
            raise HTTPException(
                status_code=400,
                detail="No se encontraron encabezados v√°lidos"
            )
        
        # 6. Insertar datos
        head_count, detail_counts = insert_dataframes(df_head, det_tables)
        
        # 7. Respuesta exitosa
        return JSONResponse(content={
            "success": True,
            "mensaje": "Importaci√≥n completada exitosamente",
            "resultados": {
                "encabezados_insertados": head_count,
                "detalles_insertados": sum(detail_counts.values()),
                "tablas_detalle": detail_counts
            },
            "archivo": file.filename
        })
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error al procesar archivo: {str(e)}"
        )
    finally:
        # Limpiar archivo temporal
        if os.path.exists(tmp_path):
            os.remove(tmp_path)


@app.get("/api/health")
async def health_check():
    """Verifica estado de conexi√≥n a BD"""
    success, error = test_connection()
    
    if success:
        return {"status": "healthy", "database": "connected"}
    else:
        return JSONResponse(
            status_code=503,
            content={"status": "unhealthy", "error": error}
        )


@app.get("/api/config")
async def get_config():
    """Obtiene configuraci√≥n actual (sin password)"""
    from core.db_manager import load_settings
    
    cfg = load_settings()
    # Ocultar password
    safe_cfg = {k: v for k, v in cfg.items() if k != 'password'}
    
    return safe_cfg
```

---

## Requisitos del Sistema

### Dependencias Python

**Archivo:** `requirements.txt`

```
pandas>=2.0.0
openpyxl>=3.1.0
SQLAlchemy>=2.0.0
pyodbc>=5.0.0
# PyQt6>=6.5.0  # No necesario para API
```

**Instalaci√≥n:**
```bash
pip install pandas openpyxl SQLAlchemy pyodbc
```

**Dependencias adicionales para API:**
```bash
# FastAPI
pip install fastapi uvicorn[standard] python-multipart

# Flask (alternativa)
pip install flask flask-cors
```

---

### Requisitos de SQL Server

1. **Versi√≥n:** SQL Server 2016 o superior
2. **Driver ODBC:** 
   - Windows: "ODBC Driver 17 for SQL Server"
   - Linux: "ODBC Driver 18 for SQL Server"
3. **Permisos de usuario:**
   - `CREATE DATABASE` (para crear BD si no existe)
   - `CREATE TABLE` (para crear tablas)
   - `INSERT`, `SELECT` (para operaciones CRUD)
4. **Autenticaci√≥n:** SQL Server Authentication (usuario/password)

**Instalaci√≥n driver ODBC:**

**Windows:**
```powershell
# Descargar desde Microsoft
https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server
```

**Linux:**
```bash
curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -
curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list > /etc/apt/sources.list.d/mssql-release.list
apt-get update
ACCEPT_EULA=Y apt-get install -y msodbcsql18
```

---

## Validaciones y Reglas de Negocio

### 1. **Validaci√≥n de Duplicados**

**Configuraci√≥n:** `settings.json` ‚Üí `"validate_duplicates": true`

**Comportamiento:**
- Verifica combinaci√≥n √∫nica de `ENCF` + `RNCEmisor`
- Si existe registro con misma combinaci√≥n, lo omite
- Previene insertar facturas duplicadas

**Desactivar:**
```json
{
  "validate_duplicates": false
}
```

---

### 2. **Limpieza de Datos**

**Valores convertidos a NULL:**
- Celdas vac√≠as
- `#e`, `#E` (errores de Excel)
- `NULL`, `null` (texto)
- `NaN`, `nan`
- Strings con solo espacios

**Ejemplo:**
```python
# Antes
"  #e  " ‚Üí None
"NULL"   ‚Üí None
""       ‚Üí None
"123"    ‚Üí "123"

# Despu√©s de limpieza
None
None
None
"123"
```

---

### 3. **Conversi√≥n de Tipos**

**Encabezado:**
- **INT:** `TipoECF`, `TipoPago`
- **BIT (booleano):** `IndicadorNotaCredito`, `IndicadorEnvioDiferido`
- **DATE:** `FechaEmision`, `FechaVencimientoSecuencia`, `FechaLimitePago`
- **DATETIME:** `fechacreacion`, `Modificado` (autom√°ticas)

**Detalle:**
- **INT:** `NumeroLinea`, `TipoECF`, `IndicadorFacturacion`
- **DECIMAL:** `CantidadItem`, `PrecioUnitarioItem`, `MontoItem`, `MontoITBISRetenido`
- **DATE:** `FechaElaboracion`, `FechaVencimientoItem`

---

### 4. **Filtrado de √çtems de Detalle**

**Regla:** Solo se insertan √≠tems con `CantidadItem` v√°lida (no NULL, no vac√≠o)

**Ejemplo:**
```
Factura E001 tiene 3 √≠tems en Excel:
- Item [1]: CantidadItem = 10    ‚Üí Se inserta
- Item [2]: CantidadItem = NULL  ‚Üí Se omite
- Item [3]: CantidadItem = 5     ‚Üí Se inserta

Resultado: 2 filas en tabla FEDetalle
```

---

## Estructura de Base de Datos

### Tabla: `FEEncabezado` (Encabezados de Facturas)

**Primary Key:** Compuesta `(ENCF, RNCEmisor)`

**Columnas principales:**
```sql
CREATE TABLE FEEncabezado (
    ENCF NVARCHAR(100) NOT NULL,          -- N√∫mero de comprobante
    RNCEmisor NVARCHAR(100) NOT NULL,     -- RNC del emisor
    TipoECF INT NULL,                     -- Tipo de comprobante
    eNCF NVARCHAR(100) NULL,              -- NCF electr√≥nico
    FechaEmision DATE NULL,               -- Fecha de emisi√≥n
    MontoTotal DECIMAL(18,4) NULL,        -- Monto total
    IndicadorNotaCredito BIT NULL,        -- Es nota de cr√©dito
    fechacreacion DATETIME NOT NULL,      -- Timestamp creaci√≥n
    Modificado DATETIME NOT NULL,         -- Timestamp modificaci√≥n
    -- ... m√°s columnas seg√∫n JSON
    PRIMARY KEY (ENCF, RNCEmisor)
);
```

---

### Tabla: `FEDetalle` (√çtems de Facturas)

**Foreign Key:** Referencia a `FEEncabezado` mediante `(eNCF, RNCEmisor)`

**Columnas principales:**
```sql
CREATE TABLE FEDetalle (
    eNCF NVARCHAR(100) NULL,              -- NCF electr√≥nico (FK)
    RNCEmisor NVARCHAR(100) NULL,         -- RNC emisor (FK)
    TipoECF INT NULL,                     -- Tipo de comprobante
    NumeroLinea INT NULL,                 -- N√∫mero de √≠tem
    CantidadItem DECIMAL(18,4) NULL,      -- Cantidad
    PrecioUnitarioItem DECIMAL(18,4) NULL,-- Precio unitario
    MontoItem DECIMAL(18,4) NULL,         -- Monto del √≠tem
    DescripcionItem NVARCHAR(500) NULL,   -- Descripci√≥n
    -- ... m√°s columnas seg√∫n JSON
);
```

**Nota:** No tiene PK definida, pero t√≠picamente se usa combinaci√≥n `(eNCF, RNCEmisor, NumeroLinea)` como identificador √∫nico.

---

## Manejo de Errores

### Errores Comunes y Soluciones

#### 1. **Error de Conexi√≥n a SQL Server**

**Error:**
```
Error de conexi√≥n: [08001] [Microsoft][ODBC Driver 17 for SQL Server]
```

**Soluciones:**
- Verificar `server` en `settings.json` (IP/hostname correcto)
- Verificar que SQL Server est√© iniciado
- Verificar firewall (puerto 1433 abierto)
- Verificar credenciales `user` y `password`
- Verificar que el driver ODBC est√© instalado

---

#### 2. **Error: "Database does not exist"**

**Error:**
```
Cannot open database "ImportarFE" requested by the login
```

**Soluci√≥n:**
```python
# Llamar antes de cualquier operaci√≥n
ensure_database_exists()
```

---

#### 3. **Error: "Invalid column name"**

**Error:**
```
Invalid column name 'FormaPago[1]'
```

**Causa:** Nombres de columnas con corchetes no est√°n siendo normalizados

**Soluci√≥n:** 
- Asegurar que `split_dataframe()` normaliza nombres
- Verificar que `encabezado_columns.json` tenga la columna definida
- Usar `_normalize_column_names()` internamente

---

#### 4. **Error: "Cannot insert NULL into column"**

**Error:**
```
Cannot insert the value NULL into column 'fechacreacion'
```

**Causa:** Columnas NOT NULL sin valor por defecto

**Soluci√≥n:**
- `fechacreacion` y `Modificado` se agregan autom√°ticamente con timestamp
- Verificar que `insert_dataframes()` est√© agregando estas columnas

---

#### 5. **Error: "Duplicate key"**

**Error:**
```
Violation of PRIMARY KEY constraint 'PK_FEEncabezado'. 
Cannot insert duplicate key in object 'dbo.FEEncabezado'. 
The duplicate key value is (E001, 123456789).
```

**Causa:** Intentar insertar registro con `ENCF` + `RNCEmisor` existente

**Soluci√≥n:**
- Habilitar validaci√≥n: `"validate_duplicates": true` en `settings.json`
- El sistema omitir√° autom√°ticamente duplicados
- Revisar logs para ver registros omitidos

---

## Logs y Debugging

### Funci√≥n: `safe_print()`

```python
def safe_print(msg: str) -> None:
    """
    Imprime mensajes protegiendo contra errores de codificaci√≥n.
    Reemplaza emojis con c√≥digos ASCII en Windows.
    """
```

**Emojis usados:**
- üóëÔ∏è `[DEL]` - Eliminando tabla
- ‚úÖ `[OK]` - Operaci√≥n exitosa
- ‚ö†Ô∏è `[WARN]` - Advertencia
- üí• `[ERROR]` - Error cr√≠tico
- üîç `[INFO]` - Informaci√≥n
- ‚öôÔ∏è `[PROC]` - Procesando
- ‚ûï `[ADD]` - Agregando columna

**Ejemplos de logs:**
```
üìã Columnas v√°lidas de encabezado en JSON: 145
üìä Transponiendo 240 columnas de detalle a formato vertical...
‚úÖ Detalle transpuesto: 1250 filas con CantidadItem v√°lida (150 filas sin cantidad eliminadas)
üîç Validando duplicados antes de insertar...
‚ö†Ô∏è Se encontraron 5 registros duplicados que ser√°n omitidos
‚úÖ Se insertar√°n 95 registros nuevos
‚úÖ Encabezado: 95 filas insertadas (agregadas a tabla existente).
```

---

## Configuraci√≥n de Columnas Adicionales

### Agregar Nueva Columna de Encabezado

1. **Editar:** `config/encabezado_columns.json`

```json
{
  "NuevaColumna": {
    "type": "NVARCHAR",
    "length": 200,
    "nullable": true,
    "description": "Descripci√≥n de la nueva columna"
  }
}
```

2. **Ejecutar:** `ensure_tables_exist(df, recreate_mode=False)`
   - El sistema detectar√° la nueva columna
   - La agregar√° autom√°ticamente a la tabla existente
   - Logs mostrar√°n: `‚ûï Columna agregada: NuevaColumna (NVARCHAR(200))`

---

### Agregar Nueva Columna de Detalle

1. **Editar:** `config/detalle_columns.json`

```json
{
  "NuevoCampo": {
    "type": "DECIMAL",
    "precision": 10,
    "scale": 2,
    "nullable": true,
    "description": "Nuevo campo de detalle"
  }
}
```

2. **Excel debe contener:** `NuevoCampo[1]`, `NuevoCampo[2]`, `NuevoCampo[3]`...
3. **Sistema autom√°ticamente:**
   - Detecta √≠ndices `[1]`, `[2]`, `[3]`...
   - Transpone a filas separadas
   - Crea columna `NuevoCampo` en tabla `FEDetalle`

---

## Mejores Pr√°cticas para Integraci√≥n API

### 1. **Manejo As√≠ncrono**

```python
from fastapi import BackgroundTasks

@app.post("/api/importar-excel-async")
async def importar_excel_async(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
):
    # Guardar archivo
    tmp_path = save_uploaded_file(file)
    
    # Procesar en background
    background_tasks.add_task(procesar_excel, tmp_path)
    
    return {"message": "Archivo en cola de procesamiento", "status": "pending"}
```

---

### 2. **Validaci√≥n de Esquema**

```python
from pydantic import BaseModel

class ConfigDB(BaseModel):
    server: str
    database: str
    user: str
    password: str
    driver: str = "ODBC Driver 17 for SQL Server"
    validate_duplicates: bool = True

@app.post("/api/config/update")
async def update_config(config: ConfigDB):
    save_settings(config.dict())
    return {"message": "Configuraci√≥n actualizada"}
```

---

### 3. **Rate Limiting**

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/importar-excel")
@limiter.limit("10/hour")  # M√°ximo 10 importaciones por hora
async def importar_excel(file: UploadFile):
    # ... l√≥gica de importaci√≥n
    pass
```

---

### 4. **Autenticaci√≥n**

```python
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi import Depends, HTTPException

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if credentials.credentials != "MI_TOKEN_SECRETO":
        raise HTTPException(status_code=401, detail="Token inv√°lido")

@app.post("/api/importar-excel")
async def importar_excel(
    file: UploadFile = File(...),
    token: str = Depends(verify_token)
):
    # ... l√≥gica protegida
    pass
```

---

### 5. **Logs Estructurados**

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('importar_dgii.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

@app.post("/api/importar-excel")
async def importar_excel(file: UploadFile):
    logger.info(f"Iniciando importaci√≥n: {file.filename}")
    try:
        # ... l√≥gica
        logger.info(f"Importaci√≥n exitosa: {head_count} registros")
    except Exception as e:
        logger.error(f"Error en importaci√≥n: {str(e)}", exc_info=True)
        raise
```

---

## Ejemplo Completo: Flask API

```python
from flask import Flask, request, jsonify
from werkzeug.utils import secure_filename
import tempfile
import os

from core.excel_loader import load_excel
from core.db_manager import (
    ensure_database_exists,
    ensure_tables_exist,
    split_dataframe,
    insert_dataframes,
    test_connection
)

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max

@app.route('/api/importar', methods=['POST'])
def importar():
    # Validar archivo
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400
    
    if not file.filename.endswith('.xlsx'):
        return jsonify({'error': 'Only .xlsx files allowed'}), 400
    
    # Par√°metros opcionales
    recreate = request.form.get('recreate', 'false').lower() == 'true'
    
    # Guardar temporal
    filename = secure_filename(file.filename)
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
        file.save(tmp.name)
        tmp_path = tmp.name
    
    try:
        # Validar conexi√≥n
        success, error = test_connection()
        if not success:
            return jsonify({'error': f'DB connection failed: {error}'}), 500
        
        # Procesar
        ensure_database_exists()
        df = load_excel(tmp_path)
        ensure_tables_exist(df, recreate_mode=recreate)
        df_head, det_tables = split_dataframe(df)
        head_count, detail_counts = insert_dataframes(df_head, det_tables)
        
        return jsonify({
            'success': True,
            'file': filename,
            'encabezados': head_count,
            'detalles': sum(detail_counts.values()),
            'tablas': detail_counts
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)

@app.route('/api/health', methods=['GET'])
def health():
    success, error = test_connection()
    if success:
        return jsonify({'status': 'healthy', 'database': 'connected'})
    else:
        return jsonify({'status': 'unhealthy', 'error': error}), 503

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
```

**Ejecutar:**
```bash
python app.py
```

**Probar:**
```bash
curl -X POST http://localhost:5000/api/importar \
  -F "file=@facturas.xlsx" \
  -F "recreate=false"
```

---

## Despliegue en Producci√≥n

### Servidor Web: Gunicorn (Linux)

```bash
# Instalar
pip install gunicorn

# Ejecutar (4 workers)
gunicorn -w 4 -b 0.0.0.0:8000 app:app
```

---

### Servidor Web: Waitress (Windows)

```bash
# Instalar
pip install waitress

# Ejecutar
waitress-serve --port=8000 app:app
```

---

### Docker Container

**Dockerfile:**
```dockerfile
FROM python:3.11-slim

# Instalar driver ODBC
RUN apt-get update && apt-get install -y \
    curl apt-transport-https gnupg unixodbc-dev && \
    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
    curl https://packages.microsoft.com/config/debian/11/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
    apt-get update && \
    ACCEPT_EULA=Y apt-get install -y msodbcsql18

WORKDIR /app

# Copiar dependencias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo (sin UI)
COPY core/ ./core/
COPY config/ ./config/
COPY app.py .

EXPOSE 8000

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:8000", "app:app"]
```

**Construir y ejecutar:**
```bash
docker build -t importar-dgii-api .
docker run -p 8000:8000 \
  -v $(pwd)/config:/app/config \
  importar-dgii-api
```

---

## Variables de Entorno (Recomendado)

**Modificar `db_manager.py` para soportar env vars:**

```python
import os

def load_settings() -> Dict[str, str]:
    # Priorizar variables de entorno
    return {
        "server": os.getenv("DB_SERVER", "localhost"),
        "database": os.getenv("DB_NAME", "ImportarFE"),
        "user": os.getenv("DB_USER", "SISTEMA"),
        "password": os.getenv("DB_PASSWORD", "@@sistema"),
        "driver": os.getenv("DB_DRIVER", "ODBC Driver 17 for SQL Server"),
        "table_encabezado": os.getenv("TABLE_ENCABEZADO", "FEEncabezado"),
        "table_detalle_prefix": os.getenv("TABLE_DETALLE_PREFIX", "FEDetalle"),
        "validate_duplicates": os.getenv("VALIDATE_DUPLICATES", "true").lower() == "true"
    }
```

**Archivo `.env`:**
```env
DB_SERVER=sql-server.example.com
DB_NAME=ImportarFE
DB_USER=api_user
DB_PASSWORD=SecurePassword123
DB_DRIVER=ODBC Driver 17 for SQL Server
VALIDATE_DUPLICATES=true
```

**Cargar con python-dotenv:**
```bash
pip install python-dotenv
```

```python
from dotenv import load_dotenv
load_dotenv()  # Cargar .env al inicio de app.py
```

---

## Resumen de Funciones Principales

| Funci√≥n | M√≥dulo | Prop√≥sito |
|---------|--------|-----------|
| `load_excel()` | `excel_loader.py` | Cargar y limpiar Excel |
| `load_settings()` | `db_manager.py` | Leer configuraci√≥n JSON |
| `save_settings()` | `db_manager.py` | Guardar configuraci√≥n JSON |
| `ensure_database_exists()` | `db_manager.py` | Crear BD si no existe |
| `ensure_tables_exist()` | `db_manager.py` | Crear/sincronizar tablas |
| `split_dataframe()` | `db_manager.py` | Dividir en encabezado/detalle |
| `insert_dataframes()` | `db_manager.py` | Insertar datos en SQL Server |
| `test_connection()` | `db_manager.py` | Probar conexi√≥n a BD |

---

## Soporte y Contacto

**Sistema:** ImportarDGII v4  
**Prop√≥sito:** Importaci√≥n de Facturaci√≥n Electr√≥nica DGII a SQL Server  
**Licencia:** Uso interno - ASESYS  

Para preguntas t√©cnicas o reportar errores, contactar al equipo de desarrollo.

---

## Changelog

### v4.0 (2024)
- ‚úÖ Soporte para validaci√≥n de duplicados por `ENCF` + `RNCEmisor`
- ‚úÖ Transposici√≥n autom√°tica de columnas indexadas `[1]`, `[2]`, `[3]`...
- ‚úÖ Sincronizaci√≥n inteligente de esquemas sin p√©rdida de datos
- ‚úÖ Conversi√≥n autom√°tica de tipos seg√∫n definiciones JSON
- ‚úÖ Filtrado de √≠tems sin `CantidadItem` v√°lida
- ‚úÖ Normalizaci√≥n de nombres de columnas (remover corchetes)
- ‚úÖ Logs estructurados con emojis/c√≥digos ASCII
- ‚úÖ Modo recrear vs modo agregar
- ‚úÖ Columnas autom√°ticas `fechacreacion` y `Modificado`

---

## Licencia

Copyright ¬© 2024 ASESYS. Todos los derechos reservados.

Este sistema es propiedad de ASESYS y est√° destinado exclusivamente para uso interno. Queda prohibida su distribuci√≥n, modificaci√≥n o uso comercial sin autorizaci√≥n expresa.
